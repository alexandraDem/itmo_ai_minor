# Задание 1. Постановка задачи

## Бизнес-постановка

Предположим, что мы разрабатываем модуль распознавания символов валют для банковского ПО. 
Такой модуль может использоваться:
- в системах проверки документов (чеки, квитанции, сканы договоров),
- в мобильном приложении банка при распознавании сфотографированных документов,
- в ПО для обмены валют, где нужно быстро определить валюту по символу.

**Бизнес-цель:**  
уменьшить количество ошибок распознавания валютных символов и сократить ручные проверки сотрудниками. 
Это должно снизить операционные затраты и уменьшает риск ошибок при работе с деньгами.

## Постановка ML-задачи

У нас есть набор изображений символов валют размером 28×28 пикселей в оттенках серого. 
Каждое изображение принадлежит к одному из классов:

- `dollar`
- `euro`
- `rupee`
- `pound`
- `yen`
- `franc`

Требуется построить модель, которая по входному изображению **определяет, какой именно символ валюты** 
из представленных на нём изображён.

Таким образом, мы решаем задачу **многоклассовой классификации** с 6 классами.

### Набор данных

https://www.kaggle.com/datasets/kishanj/currency-symbol-datasets/data

Каждый объект — это картинка 64×64 (784 признака — яркости пикселей).  
Целевая переменная — номер класса от 0 до 5, где соответствие метки и названия класса задаётся списком:

- `classes = ["dollar", "euro", "rupee", "pound", "yen", "franc"]`

# Задание 2. Выбор  метрики качества

Так как у нас **многоклассовая классификация** с 6 классами валют, важно учитывать качество распознавания **для каждого класса**, а не только общую долю правильных ответов.

В качестве основной метрики выбираем:

- **F1-score (macro)** — макроусреднённый F1 по всем классам.

**Почему именно F1-macro:**

- F1 учитывает и **precision**, и **recall**, то есть одновременно штрафует за ложные срабатывания 
  и за пропуски.
- Макроусреднение даёт **равный вес каждому классу**, даже если распределение по классам  немного неравномерное. Это важно, чтобы, например, модель хорошо различала не только самый   частый символ, но и более редкие.

Дополнительно будем смотреть на:

- **Accuracy (доля верных ответов)** — понятная и наглядная метрика, которая показывает, в какой доле случаев модель вообще не ошиблась.

В итоге:  
- для подробного анализа и сравнения моделей используем в качестве основной метрики используем **F1-macro**,  
- для общей  оценки дополнительно — **accuracy**.

